{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "13f899f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python \n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Mapping, List\n",
    "from pprint import pprint\n",
    "import plotly.express as px\n",
    "\n",
    "# Numpy and Pandas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Transformers \n",
    "from transformers import AutoTokenizer, AutoModel, TrainingArguments, Trainer, AutoConfig\n",
    "\n",
    "# Catalyst\n",
    "from catalyst.dl import SupervisedRunner, Runner\n",
    "from catalyst.callbacks import AccuracyCallback, AUCCallback, OptimizerCallback\n",
    "from catalyst.callbacks import CheckpointCallback\n",
    "from catalyst.utils import set_global_seed, prepare_cudnn, load_checkpoint, unpack_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c2e52704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "38c9b47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.18.0'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a491c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0c880784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reproduce, download the data and customize this path\n",
    "PATH_TO_MODEL = '/home/timur/Desktop/jupyter_wf/bert-finetuning-catalyst/logdir/model.best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "50321580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reproduce, download the data and customize this path\n",
    "PATH_TO_DATA = '/home/timur/Desktop/jupyter_wf/contacts-in-item-TimuJ/model_notebook/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0ae84f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(PATH_TO_DATA + 'train.csv').fillna('')\n",
    "valid_df = pd.read_csv(PATH_TO_DATA + 'valid.csv').fillna('')\n",
    "test_df = pd.read_csv(PATH_TO_DATA + 'test.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "765135a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>datetime_submitted</th>\n",
       "      <th>is_bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11365</td>\n",
       "      <td>AirPods</td>\n",
       "      <td>Airpods /\\nAirPods 2 CАMAЯ ЛУЧШAЯ и ТOЧНАЯ КOПИЯ оригинала - 5:5, ПОCЛEДНЯЯ MОДЕЛЬ - октябрь 205...</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>3489.0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2019-10-13 12:43:42.299084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11366</td>\n",
       "      <td>Механизм стеклоочистителя передний Nissan Serena 4</td>\n",
       "      <td>Механизм стеклоочистителя Nissan Serena 1 C62M GA13DE 1991 передний (б/у)/\\n/\\n Марка: Nissan/\\n...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>Липецкая область</td>\n",
       "      <td>Липецк</td>\n",
       "      <td>2019-10-13 12:45:06.628388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11367</td>\n",
       "      <td>Нш-42в-4л</td>\n",
       "      <td>новое. тел 89024003360</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>Челябинская область</td>\n",
       "      <td>Челябинск</td>\n",
       "      <td>2019-10-13 12:45:44.957825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11368</td>\n",
       "      <td>Шины</td>\n",
       "      <td>Два ската DUNLOP Япония 683 -53-63 состояние новых использовались один сезон 1 месяца цена за 2 ...</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Пролетарск</td>\n",
       "      <td>2019-10-13 12:45:45.456624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11369</td>\n",
       "      <td>Живые раки</td>\n",
       "      <td>В продаже рак дикий, речной./\\nОптом от 50 кг, в розницу от 5 кг./\\nЦена опт / розница:/\\n/\\nмел...</td>\n",
       "      <td>Продукты питания</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Россия</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2019-10-13 12:48:10.767700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>16232</td>\n",
       "      <td>Офисное помещение</td>\n",
       "      <td>Сдаются офисное помещение по Ул Калинина 80. Помещения находятся в офисном центре. В стоимость а...</td>\n",
       "      <td>Коммерческая недвижимость</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>Чувашия</td>\n",
       "      <td>Чебоксары</td>\n",
       "      <td>2019-10-14 23:57:30.094904</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>16233</td>\n",
       "      <td>iPhone 8 Plus Silver 25GB</td>\n",
       "      <td>Оригинальный ростест айфон. Идеальное состояние, ни разу не ремонтировался и не разбирался. /\\nК...</td>\n",
       "      <td>Телефоны</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Казань</td>\n",
       "      <td>2019-10-14 23:57:50.610616</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>16234</td>\n",
       "      <td>6-к квартира, 54 м², 5/9 эт.</td>\n",
       "      <td>_________________________________________________________/\\n /\\nПРОСТОРНАЯ КВАРТИРА С ХОРОШЕЙ ПЛ...</td>\n",
       "      <td>Квартиры</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>3300000.0</td>\n",
       "      <td>Ставропольский край</td>\n",
       "      <td>Пятигорск</td>\n",
       "      <td>2019-10-14 23:58:02.781579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>16235</td>\n",
       "      <td>4-к квартира, 60 м², 9/9 эт.</td>\n",
       "      <td>/\\n /\\n● Работаем БЕЗ ПЕРЕРЫВОВ И ВЫХОДНЫХ с 9:00 до 12:00./\\n /\\n● Обменяем и продадим Вашу не...</td>\n",
       "      <td>Квартиры</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>2300000.0</td>\n",
       "      <td>Ставропольский край</td>\n",
       "      <td>Пятигорск</td>\n",
       "      <td>2019-10-14 23:59:01.435691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>16236</td>\n",
       "      <td>BMW 7 серия, 1031</td>\n",
       "      <td>Машина технически в отличном состояние все системы работают все исправно🛠🔩,машина ухоженная отли...</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>1550000.0</td>\n",
       "      <td>Нижегородская область</td>\n",
       "      <td>Нижний Новгород</td>\n",
       "      <td>2019-10-14 23:59:31.048375</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4872 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               title  \\\n",
       "0          11365                                             AirPods   \n",
       "1          11366  Механизм стеклоочистителя передний Nissan Serena 4   \n",
       "2          11367                                           Нш-42в-4л   \n",
       "3          11368                                                Шины   \n",
       "4          11369                                          Живые раки   \n",
       "...          ...                                                 ...   \n",
       "4867       16232                                   Офисное помещение   \n",
       "4868       16233                           iPhone 8 Plus Silver 25GB   \n",
       "4869       16234                        6-к квартира, 54 м², 5/9 эт.   \n",
       "4870       16235                        4-к квартира, 60 м², 9/9 эт.   \n",
       "4871       16236                                   BMW 7 серия, 1031   \n",
       "\n",
       "                                                                                              description  \\\n",
       "0     Airpods /\\nAirPods 2 CАMAЯ ЛУЧШAЯ и ТOЧНАЯ КOПИЯ оригинала - 5:5, ПОCЛEДНЯЯ MОДЕЛЬ - октябрь 205...   \n",
       "1     Механизм стеклоочистителя Nissan Serena 1 C62M GA13DE 1991 передний (б/у)/\\n/\\n Марка: Nissan/\\n...   \n",
       "2                                                                                  новое. тел 89024003360   \n",
       "3     Два ската DUNLOP Япония 683 -53-63 состояние новых использовались один сезон 1 месяца цена за 2 ...   \n",
       "4     В продаже рак дикий, речной./\\nОптом от 50 кг, в розницу от 5 кг./\\nЦена опт / розница:/\\n/\\nмел...   \n",
       "...                                                                                                   ...   \n",
       "4867  Сдаются офисное помещение по Ул Калинина 80. Помещения находятся в офисном центре. В стоимость а...   \n",
       "4868  Оригинальный ростест айфон. Идеальное состояние, ни разу не ремонтировался и не разбирался. /\\nК...   \n",
       "4869  _________________________________________________________/\\n /\\nПРОСТОРНАЯ КВАРТИРА С ХОРОШЕЙ ПЛ...   \n",
       "4870   /\\n /\\n● Работаем БЕЗ ПЕРЕРЫВОВ И ВЫХОДНЫХ с 9:00 до 12:00./\\n /\\n● Обменяем и продадим Вашу не...   \n",
       "4871  Машина технически в отличном состояние все системы работают все исправно🛠🔩,машина ухоженная отли...   \n",
       "\n",
       "                    subcategory             category      price  \\\n",
       "0                 Аудио и видео  Бытовая электроника     3489.0   \n",
       "1         Запчасти и аксессуары            Транспорт     2500.0   \n",
       "2         Запчасти и аксессуары            Транспорт     3000.0   \n",
       "3         Запчасти и аксессуары            Транспорт     4000.0   \n",
       "4              Продукты питания      Для дома и дачи      400.0   \n",
       "...                         ...                  ...        ...   \n",
       "4867  Коммерческая недвижимость         Недвижимость     9200.0   \n",
       "4868                   Телефоны  Бытовая электроника    20000.0   \n",
       "4869                   Квартиры         Недвижимость  3300000.0   \n",
       "4870                   Квартиры         Недвижимость  2300000.0   \n",
       "4871                 Автомобили            Транспорт  1550000.0   \n",
       "\n",
       "                     region             city          datetime_submitted  \\\n",
       "0                    Россия           Москва  2019-10-13 12:43:42.299084   \n",
       "1          Липецкая область           Липецк  2019-10-13 12:45:06.628388   \n",
       "2       Челябинская область        Челябинск  2019-10-13 12:45:44.957825   \n",
       "3        Ростовская область       Пролетарск  2019-10-13 12:45:45.456624   \n",
       "4                    Россия           Москва  2019-10-13 12:48:10.767700   \n",
       "...                     ...              ...                         ...   \n",
       "4867                Чувашия        Чебоксары  2019-10-14 23:57:30.094904   \n",
       "4868              Татарстан           Казань  2019-10-14 23:57:50.610616   \n",
       "4869    Ставропольский край        Пятигорск  2019-10-14 23:58:02.781579   \n",
       "4870    Ставропольский край        Пятигорск  2019-10-14 23:59:01.435691   \n",
       "4871  Нижегородская область  Нижний Новгород  2019-10-14 23:59:31.048375   \n",
       "\n",
       "      is_bad  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          1  \n",
       "4          0  \n",
       "...      ...  \n",
       "4867       0  \n",
       "4868       0  \n",
       "4869       0  \n",
       "4870       0  \n",
       "4871       1  \n",
       "\n",
       "[4872 rows x 10 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "24bcb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'DeepPavlov/distilrubert-base-cased-conversational' # pretrained model from Transformers\n",
    "LOG_DIR = \"./logdir_avito_descr\"    # for training logs and tensorboard visualizations\n",
    "NUM_EPOCHS = 5                         # smth around 2-6 epochs is typically fine when finetuning transformers\n",
    "BATCH_SIZE = 8                        # depends on your available GPU memory (in combination with max seq length)\n",
    "MAX_SEQ_LENGTH = 256                   # depends on your available GPU memory (in combination with batch size)\n",
    "LEARN_RATE = 1e-5                      # learning rate is typically ~1e-5 for transformers\n",
    "ACCUM_STEPS = 4                        # one optimization step for that many backward passes\n",
    "SEED = 31                              # random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8307395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrapper around Torch Dataset to perform text classification\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 texts: List[str],\n",
    "                 labels: List[str] = None,\n",
    "                 label_dict: Mapping[str, int] = None,\n",
    "                 max_seq_length: int = 256,\n",
    "                 model_name: str = 'DeepPavlov/distilrubert-base-cased-conversational'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            texts (List[str]): a list with texts to classify or to train the\n",
    "                classifier on\n",
    "            labels List[str]: a list with classification labels (optional)\n",
    "            label_dict (dict): a dictionary mapping class names to class ids,\n",
    "                to be passed to the validation data (optional)\n",
    "            max_seq_length (int): maximal sequence length in tokens,\n",
    "                texts will be stripped to this length\n",
    "            model_name (str): transformer model name, needed to perform\n",
    "                appropriate tokenization\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.label_dict = label_dict\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        if self.label_dict is None and labels is not None:\n",
    "            # {'class1': 0, 'class2': 1, 'class3': 2, ...}\n",
    "            # using this instead of `sklearn.preprocessing.LabelEncoder`\n",
    "            # no easily handle unknown target values\n",
    "            self.label_dict = dict(zip(sorted(set(labels)),\n",
    "                                       range(len(set(labels)))))\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # suppresses tokenizer warnings\n",
    "        logging.getLogger(\n",
    "            \"transformers.tokenization_utils\").setLevel(logging.FATAL)\n",
    "\n",
    "        # special tokens for transformers\n",
    "        # in the simplest case a [CLS] token is added in the beginning\n",
    "        # and [SEP] token is added in the end of a piece of text\n",
    "        # [CLS] <indexes text tokens> [SEP] .. <[PAD]>\n",
    "        self.sep_vid = self.tokenizer.vocab[\"[SEP]\"]\n",
    "        self.cls_vid = self.tokenizer.vocab[\"[CLS]\"]\n",
    "        self.pad_vid = self.tokenizer.vocab[\"[PAD]\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            int: length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index) -> Mapping[str, torch.Tensor]:\n",
    "        \"\"\"Gets element of the dataset\n",
    "\n",
    "        Args:\n",
    "            index (int): index of the element in the dataset\n",
    "        Returns:\n",
    "            Single element by index\n",
    "        \"\"\"\n",
    "\n",
    "        # encoding the text\n",
    "        x = self.texts[index]\n",
    "        x_encoded = self.tokenizer.encode(\n",
    "            x,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_length,\n",
    "            return_tensors=\"pt\",\n",
    "        ).squeeze(0)\n",
    "\n",
    "        # padding short texts\n",
    "        true_seq_length = x_encoded.size(0)\n",
    "        pad_size = self.max_seq_length - true_seq_length\n",
    "        pad_ids = torch.Tensor([self.pad_vid] * pad_size).long()\n",
    "        x_tensor = torch.cat((x_encoded, pad_ids))\n",
    "\n",
    "        # dealing with attention masks - there's a 1 for each input token and\n",
    "        # if the sequence is shorter that `max_seq_length` then the rest is\n",
    "        # padded with zeroes. Attention mask will be passed to the model in\n",
    "        # order to compute attention scores only with input data\n",
    "        # ignoring padding\n",
    "        mask = torch.ones_like(x_encoded, dtype=torch.int8)\n",
    "        mask_pad = torch.zeros_like(pad_ids, dtype=torch.int8)\n",
    "        mask = torch.cat((mask, mask_pad))\n",
    "\n",
    "        output_dict = {\n",
    "            'features' : x_tensor,\n",
    "            'attention_mask' : mask\n",
    "        }\n",
    "\n",
    "        # encoding target\n",
    "        if self.labels is not None:\n",
    "            y = self.labels[index]\n",
    "            y_encoded = torch.Tensor(\n",
    "                [self.label_dict.get(y, -1)]\n",
    "            ).long().squeeze(0)\n",
    "            output_dict[\"targets\"] = y_encoded\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "782eef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextClassificationDataset(\n",
    "    texts=train_df['description'].values.tolist(),\n",
    "    labels=train_df['is_bad'].values.tolist(),\n",
    "    label_dict=None,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "valid_dataset = TextClassificationDataset(\n",
    "    texts=valid_df['description'].values.tolist(),\n",
    "    labels=valid_df['is_bad'].values.tolist(),\n",
    "    label_dict=train_dataset.label_dict,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n",
    "test_dataset = TextClassificationDataset(\n",
    "    texts=test_df['description'].values.tolist(),\n",
    "    labels=None,\n",
    "    label_dict=None,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    model_name=MODEL_NAME\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7994fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(train_dataset.label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "03769946",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_loaders = {\n",
    "    \"train\": DataLoader(dataset=train_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=True),\n",
    "    \"valid\": DataLoader(dataset=valid_dataset,\n",
    "                        batch_size=BATCH_SIZE, \n",
    "                        shuffle=False)    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "313e0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = {\n",
    "    \"test\": DataLoader(\n",
    "            dataset=test_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4128d3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BertForSequenceClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified version of the same class by HuggingFace.\n",
    "    See transformers/modeling_distilbert.py in the transformers repository.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretrained_model_name: str, num_classes: int = None, dropout: float = 0.3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pretrained_model_name (str): HuggingFace model name.\n",
    "                See transformers/modeling_auto.py\n",
    "            num_classes (int): the number of class labels\n",
    "                in the classification task\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(pretrained_model_name, num_labels=num_classes)\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name, config=config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, features, attention_mask=None, head_mask=None):\n",
    "        \"\"\"Compute class probabilities for the input sequence.\n",
    "\n",
    "        Args:\n",
    "            features (torch.Tensor): ids of each token,\n",
    "                size ([bs, seq_length]\n",
    "            attention_mask (torch.Tensor): binary tensor, used to select\n",
    "                tokens which are used to compute attention scores\n",
    "                in the self-attention heads, size [bs, seq_length]\n",
    "            head_mask (torch.Tensor): 1.0 in head_mask indicates that\n",
    "                we keep the head, size: [num_heads]\n",
    "                or [num_hidden_layers x num_heads]\n",
    "        Returns:\n",
    "            PyTorch Tensor with predicted class scores\n",
    "        \"\"\"\n",
    "        assert attention_mask is not None, \"attention mask is none\"\n",
    "\n",
    "        # taking BERTModel output\n",
    "        # see https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel\n",
    "        bert_output = self.model(input_ids=features, attention_mask=attention_mask, head_mask=head_mask)\n",
    "        # we only need the hidden state here and don't need\n",
    "        # transformer output, so index 0\n",
    "        seq_output = bert_output[0]  # (bs, seq_len, dim)\n",
    "        # mean pooling, i.e. getting average representation of all tokens\n",
    "        pooled_output = seq_output.mean(axis=1)  # (bs, dim)\n",
    "        pooled_output = self.dropout(pooled_output)  # (bs, dim)\n",
    "        scores = self.classifier(pooled_output)  # (bs, num_classes)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c672c",
   "metadata": {},
   "source": [
    "## Loading pth model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "707b4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/distilrubert-base-cased-conversational were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (model): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = BertForSequenceClassification(pretrained_model_name=MODEL_NAME, num_classes=2)\n",
    "model.load_state_dict(torch.load(PATH_TO_MODEL))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "21aa90f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (model): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "580faa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SupervisedRunner(model=model, input_key=(\"features\", \"attention_mask\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3015b971",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3deced65",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'softmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8917/1220421257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m test_pred_scores = np.concatenate(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/tmp/ipykernel_8917/1220421257.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m test_pred_scores = np.concatenate(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'softmax'"
     ]
    }
   ],
   "source": [
    "test_pred_scores = np.concatenate(\n",
    "    [pred[\"logits\"].detach().cpu().numpy() for pred in runner.predict_loader(loader=test_loaders[\"test\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ef2fd50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_probs = F.softmax(torch.from_numpy(test_pred_scores), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cf18b8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.9508769e-05, 6.7123474e-05, 9.9641681e-01, ..., 2.0889622e-04,\n",
       "       9.8866665e-05, 9.8717308e-01], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score_probs[:, -1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "90654c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_score_probs[:, -1].numpy(), columns=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e8c53aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e8e85db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['perdiction'] = test_score_probs[:, -1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "15012ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>prediction</th>\n",
       "      <th>perdiction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.996417</td>\n",
       "      <td>0.996417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998438</td>\n",
       "      <td>0.998438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.001098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>4867</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4868</th>\n",
       "      <td>4868</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4869</th>\n",
       "      <td>4869</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>4870</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4871</th>\n",
       "      <td>4871</td>\n",
       "      <td>0.987173</td>\n",
       "      <td>0.987173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4872 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  prediction  perdiction\n",
       "0         0    0.000080    0.000080\n",
       "1         1    0.000067    0.000067\n",
       "2         2    0.996417    0.996417\n",
       "3         3    0.998438    0.998438\n",
       "4         4    0.001098    0.001098\n",
       "...     ...         ...         ...\n",
       "4867   4867    0.000361    0.000361\n",
       "4868   4868    0.000079    0.000079\n",
       "4869   4869    0.000209    0.000209\n",
       "4870   4870    0.000099    0.000099\n",
       "4871   4871    0.987173    0.987173\n",
       "\n",
       "[4872 rows x 3 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf31fce",
   "metadata": {},
   "source": [
    "## Evaluating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "47f8bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a28183b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = sorted(train_df['is_bad'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b6dfaf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = [LABELS[i] for i in test_pred_scores.argmax(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b1dd98a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9350010735567987"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_df['is_bad'], test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c53424fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c0565e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Sun Aug 28 18:19:06 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   61C    P0    43W /  N/A |   4002MiB /  6144MiB |     94%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1671      G   /usr/lib/xorg/Xorg                 64MiB |\r\n",
      "|    0   N/A  N/A      2623      G   /usr/lib/xorg/Xorg                212MiB |\r\n",
      "|    0   N/A  N/A      2803      G   /usr/bin/gnome-shell               42MiB |\r\n",
      "|    0   N/A  N/A      4954      G   /usr/lib/firefox/firefox          298MiB |\r\n",
      "|    0   N/A  N/A      5031      G   telegram-desktop                    1MiB |\r\n",
      "|    0   N/A  N/A      8917      C   /usr/bin/python3                 3359MiB |\r\n",
      "|    0   N/A  N/A     13164      G   ...RendererForSitePerProcess        9MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ed64d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140e5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734fbffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d61936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3592d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
